{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8573597e-37ba-4c1e-bf3d-20cfb49d7ceb",
   "metadata": {},
   "source": [
    "# Mirror Staged Landsat L1C Demo Collections\n",
    "\n",
    "\n",
    "**Purpose:** This notebook provides a way to mirror hand-curated demo collections and items from the staging catalog to the production catalog. The original curation work is captured veda-data [veda-data/transformation-scripts/landsat-lakes-discovery](https://github.com/NASA-IMPACT/veda-data/tree/main/transformation-scripts/landsat-lakes-discovery) but because these collections have been corrected over time, this notebook will use the staging STAC catalog as the source of truth.\n",
    "\n",
    "> Assertions\n",
    "> (1) The STAC Item assets are hosted externally so cannot be ingested via VEDA's discovery pipeline AND\n",
    "> (2) The staging (or source) catalog has extensive hand-curated metadata that we want to mirror exactly rather than re-create.\n",
    "> (3) We are making some some one-off corrections to some one-off hand-curated collections, read comments if attempting to generalize for wider usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eb4069-638e-4771-b712-ef78b787b6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from pystac_client import Client\n",
    "from pystac import Collection, Item\n",
    "\n",
    "SRC_STAC_API_URL = \"https://staging-stac.delta-backend.com\"\n",
    "TARGET_STAC_API_URL = \"https://test.openveda.cloud/api/stac\"\n",
    "TARGET_INGEST_API_URL = \"https://test.openveda.cloud/api/ingest\"\n",
    "\n",
    "catalog = Client.open(SRC_STAC_API_URL)\n",
    "\n",
    "TOKEN = \"SECRET\"\n",
    "authorization_header = f\"Bearer {TOKEN}\"\n",
    "headers = {\n",
    "    \"Authorization\": authorization_header,\n",
    "    \"content-type\": \"application/json\",\n",
    "    \"accept\": \"application/json\",\n",
    "}\n",
    "authme_url = f\"{TARGET_INGEST_API_URL}/auth/me\"\n",
    "response = requests.get(authme_url, headers=headers)\n",
    "response.reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce1ad1f-3971-43b3-b04b-3548a9af61f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_collection_ids = [\n",
    "    'landsat-c2l2-sr-antarctic-glaciers-pine-island',\n",
    "    'landsat-c2l2-sr-antarctic-glaciers-thwaites',\n",
    "    'landsat-c2l2-sr-lakes-aral-sea',\n",
    "    'landsat-c2l2-sr-lakes-lake-balaton',\n",
    "    'landsat-c2l2-sr-lakes-lake-biwa',\n",
    "    'landsat-c2l2-sr-lakes-tonle-sap',\n",
    "    'landsat-c2l2-sr-lakes-vanern'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440774e9-0833-424f-b62c-4df967924423",
   "metadata": {},
   "source": [
    "## Part 1 Mirror the collection metadata\n",
    "\n",
    "1. Strip hierarchical and self links to the src catalog\n",
    "2. Strip `cog_default` item_asset (a bug for these landsat collections)\n",
    "3. Save file for veda-data/ingestion_inputs/production/collections\n",
    "4. Validate and write collection to target catalog via the authenticated `{TARGET_INGEST_API_URL}/collections` endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3c723e-df35-4aed-abb1-f9c1dc78909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dry_run = True\n",
    "\n",
    "for collection_id in src_collection_ids:\n",
    "\n",
    "    # We will also archive the corrected collection to the veda-data repo\n",
    "    outfile = f\"{collection_id}.json\"\n",
    "\n",
    "    src_collection = catalog.get_collection(collection_id)\n",
    "    \n",
    "    # Strip the catalog links that are dynamically rendered by the source STAC API\n",
    "    src_collection.remove_hierarchical_links()\n",
    "    \n",
    "    # Start the new collection we will publish\n",
    "    collection_dict = src_collection.to_dict(include_self_link=False)\n",
    "\n",
    "    # Special case for these landsat collections: cog_default assets were mistakenly added to item_assets so fix it\n",
    "    item_assets = collection_dict.get(\"item_assets\")\n",
    "    item_assets.pop(\"cog_default\", None)\n",
    "    collection_dict[\"item_assets\"] = item_assets\n",
    "\n",
    "    # Make sure the summaries object from the staged collection is included in the veda-data record (TODO check why this isn't passed through pystac to_dict)\n",
    "    collection_dict[\"summaries\"] = src_collection.summaries._summaries\n",
    "\n",
    "    # Validate\n",
    "    collection = Collection.from_dict(collection_dict)\n",
    "    collection.validate()\n",
    "\n",
    "    # Save to file\n",
    "    Path(outfile).write_text(\n",
    "        json.dumps(collection_dict, indent=4) + '\\n'\n",
    "    )\n",
    "\n",
    "    # Publish to target STAC catalog\n",
    "    publish_url = f\"{TARGET_INGEST_API_URL}/collections\"\n",
    "    if not dry_run:\n",
    "        publish_response = requests.post(\n",
    "            publish_url, \n",
    "            headers=headers,\n",
    "            json=collection_dict\n",
    "        )\n",
    "        print(f\"{collection_id=} {publish_response.reason=}\")\n",
    "    else:\n",
    "        print(f\"POST {publish_url} {collection_id=} {dry_run=}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7775985f-df14-41a8-a69e-a2aba18dc8c1",
   "metadata": {},
   "source": [
    "# Part 2 mirror item metadata\n",
    "\n",
    "> Instead of having a super long and unreadable loop, iterate over the source collections one more time to get items to mirror\n",
    "\n",
    "1. Strip hierarchical and self links to the src catalog\n",
    "2. Validate and write item to target catalog via the authenticated `{TARGET_INGEST_API_URL}/ingestions` endpoint (ingestor lambda validates items before loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9df7f0-308b-4cc9-9268-55a8a5812047",
   "metadata": {},
   "outputs": [],
   "source": [
    "dry_run = False\n",
    "\n",
    "for collection_id in src_collection_ids:\n",
    "\n",
    "    search = catalog.search(collections=[collection_id])\n",
    "    src_item_collection = search.item_collection()\n",
    "    print(f\"Found {len(src_item_collection)} items for {collection_id=}\")\n",
    "\n",
    "    for src_item in src_item_collection.items:\n",
    "\n",
    "        # Strip the catalog links that are dynamically rendered by the source STAC API\n",
    "        src_item.remove_hierarchical_links()\n",
    "\n",
    "        # Start the new item we will publish\n",
    "        item_dict = src_item.to_dict(include_self_link=False)\n",
    "\n",
    "        # Add collection link\n",
    "        links = item_dict[\"links\"]\n",
    "        links.append({\n",
    "            \"rel\": \"collection\",\n",
    "            \"href\": collection_id,\n",
    "            \"type\": \"application/json\"\n",
    "        })\n",
    "        item_dict[\"links\"] = links\n",
    "\n",
    "        # Validate\n",
    "        item = Item.from_dict(item_dict)\n",
    "        item.validate()\n",
    "    \n",
    "        # Special case for these landsat collections: cog_default assets were mistakenly added to item_assets so fix it\n",
    "        item_assets = item_dict.get(\"assets\")\n",
    "        item_assets.pop(\"cog_default\", None)\n",
    "        item_dict[\"assets\"] = item_assets\n",
    "\n",
    "        # Publish to target STAC catalog\n",
    "        publish_url = f\"{TARGET_INGEST_API_URL}/ingestions\"\n",
    "        if not dry_run:\n",
    "            publish_response = requests.post(\n",
    "                publish_url, \n",
    "                headers=headers,\n",
    "                json=item_dict\n",
    "            )\n",
    "            print(f\"POST {publish_url} {collection_id=}\\n{item_dict['id']=} {publish_response.reason=}\")\n",
    "        else:\n",
    "            print(f\"POST {publish_url} {collection_id=}\\n{item_dict['id']=} {dry_run=}\")      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6755a124-042b-4070-bd12-5654f34ff341",
   "metadata": {},
   "source": [
    "## Part 3 Check the target STAC catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d922785-dc2c-4bea-8205-5f69a47b68c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_catalog = Client.open(SRC_STAC_API_URL)\n",
    "target_catalog = Client.open(TARGET_STAC_API_URL)\n",
    "\n",
    "for collection_id in src_collection_ids:\n",
    "\n",
    "    src_collection = src_catalog.get_collection(collection_id)\n",
    "    src_matched = \"TODO\"\n",
    "    target_collection = target_catalog.get_collection(collection_id)\n",
    "    target_matched = \"TODO\"\n",
    "\n",
    "    print(f\"\\n{collection_id} {src_matched=} {target_matched=}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25761492-69fd-4987-a93b-e52b7d7990eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
